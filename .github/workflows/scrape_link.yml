name: Scrape YF Links

on:
  schedule:
    - cron: '30 */6 * * *'  # Runs every 6 hours offset by 30 minutes (at 00:30, 06:30, 12:30, 18:30, etc.)
  workflow_dispatch:

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v2

    - name: Set up Python environment
      uses: actions/setup-python@v2
      with:
        python-version: '3.12'

    - name: Install Chrome
      run: |
        wget https://mirror.cs.uchicago.edu/google-chrome/pool/main/g/google-chrome-stable/google-chrome-stable_114.0.5735.90-1_amd64.deb
        sudo apt-get install -y --allow-downgrades ./google-chrome-stable_114.0.5735.90-1_amd64.deb

    - name: Install ChromeDriver
      run: |
        CHROME_VERSION=$(google-chrome-stable --version | awk '{ print $3 }' | awk -F'.' '{ print $1 }')
        wget https://chromedriver.storage.googleapis.com/114.0.5735.90/chromedriver_linux64.zip
        unzip chromedriver_linux64.zip
        sudo mv chromedriver /usr/bin/chromedriver
        sudo chmod +x /usr/bin/chromedriver

    - name: Install dependencies
      run: |
        pip install -r requirements.txt

    - name: Run Python script
      run: python extract_text.py

    - name: Calculate and Update README
      run: |
        PLACEHOLDER=$(python calculate.py "unscraped")
        sed -i "s/UNSCRAPED_LINKS/${PLACEHOLDER}/g" README.md

    - name: Commit changes to scraped_text.json
      run: |
        git config user.name "GitHub Actions Bot"
        git config user.email "<>"
        git add scraped_text.json
        git add README.md # update unscraped link count
        TODAY_DATE=$(date +'%Y-%m-%d')
        git commit -m "Update scraped_text.json - $TODAY_DATE"
        git push origin main  # Assuming you want to push to the master branch
